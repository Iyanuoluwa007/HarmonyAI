{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cce3381-3c13-4d2c-bee0-b5572de9f032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders ready \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# your confirmed paths\n",
    "csv_path   = \"data/spotify_dataset.csv\"\n",
    "json1_path = \"data/900k Definitive Spotify Dataset.json\"\n",
    "json2_path = \"data/final_milliondataset_BERT_500K_revised.json\"\n",
    "\n",
    "# outputs\n",
    "Path(\"data/interim\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"app/artifacts\").mkdir(parents=True, exist_ok=True)\n",
    "print(\"Folders ready \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a36c8fb1-1cb5-49ca-9b0b-36da4227f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_jsonl(path, n=None):\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if not line: \n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                try:\n",
    "                    rows.append(json.loads(line.replace(\"\\\\/\", \"/\")))\n",
    "                except Exception:\n",
    "                    continue\n",
    "            if n and (i+1) >= n:\n",
    "                break\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def to_float(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower().replace(\"db\",\"\").replace(\"âˆ’\",\"-\")\n",
    "    s = re.sub(\",\", \"\", s)\n",
    "    m = re.search(r\"[-+]?\\d*\\.?\\d+\", s)\n",
    "    return float(m.group(0)) if m else np.nan\n",
    "\n",
    "def parse_tempo(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    v = to_float(x)\n",
    "    if v is np.nan: return np.nan\n",
    "    return 40.0 + v*(220.0-40.0) if 0 < v <= 1.0 else v\n",
    "\n",
    "def parse_loudness_db(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    v = to_float(x)\n",
    "    if v is np.nan: return np.nan\n",
    "    return -30.0 + v*30.0 if 0 <= v <= 1.0 else v\n",
    "\n",
    "def parse_length_mmss(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip()\n",
    "    m = re.match(r\"^\\s*(\\d{1,2}):(\\d{1,2})\\s*$\", s)\n",
    "    if m: return int(m.group(1))*60 + int(m.group(2))\n",
    "    try: return float(s)\n",
    "    except: return np.nan\n",
    "\n",
    "_MONTHS = {m:i for i,m in enumerate(\n",
    "    [\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\"july\",\"august\",\"september\",\"october\",\"november\",\"december\"],1)}\n",
    "def parse_release_date(x):\n",
    "    if pd.isna(x): return pd.NaT\n",
    "    s = str(x).strip()\n",
    "    ts = pd.to_datetime(s, errors=\"ignore\")\n",
    "    if isinstance(ts, pd.Timestamp): return ts\n",
    "    s2 = re.sub(r\"(\\d+)(st|nd|rd|th)\", r\"\\1\", s.lower())\n",
    "    m = re.match(r\"^\\s*(\\d{1,2})\\s+([a-z]+)\\s+(\\d{4})\\s*$\", s2)\n",
    "    if m:\n",
    "        day = int(m.group(1)); mon = _MONTHS.get(m.group(2)); year = int(m.group(3))\n",
    "        if mon:\n",
    "            try: return pd.Timestamp(year, mon, day)\n",
    "            except: return pd.NaT\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def norm_key(s):\n",
    "    if pd.isna(s): return \"\"\n",
    "    return re.sub(r\"\\s+\",\" \", str(s).strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db2988cd-ab80-4363-9019-d1faab4b1057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json2: (551443, 33) | json1: (498052, 31) | csv: (551443, 39)\n"
     ]
    }
   ],
   "source": [
    "df_j2 = read_jsonl(json2_path)             # revised BERT 500K (primary)\n",
    "df_j1 = read_jsonl(json1_path)\n",
    "df_csv = pd.read_csv(csv_path, low_memory=False)\n",
    "print(\"json2:\", df_j2.shape, \"| json1:\", df_j1.shape, \"| csv:\", df_csv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd9f9f3-87a6-4c5c-af06-dff0f2774568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isrc</th>\n",
       "      <td>GBBPW1200312</td>\n",
       "      <td>GBBPW1200314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist</th>\n",
       "      <td>!!!</td>\n",
       "      <td>!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_name</th>\n",
       "      <td>Even When the Waters Cold</td>\n",
       "      <td>One Girl / One Boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyrics</th>\n",
       "      <td>Friends told her she was better off at the bot...</td>\n",
       "      <td>Well I heard it, playing soft\\nFrom a drunken ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <td>hip hop</td>\n",
       "      <td>hip hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>album</th>\n",
       "      <td>Thr!!!er</td>\n",
       "      <td>Thr!!!er</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release_date</th>\n",
       "      <td>29th April 2013</td>\n",
       "      <td>29th April 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>D min</td>\n",
       "      <td>A# min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_signature</th>\n",
       "      <td>4/4</td>\n",
       "      <td>4/4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>03:47</td>\n",
       "      <td>04:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explicit</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <td>sadness</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempo</th>\n",
       "      <td>105</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loudness_db</th>\n",
       "      <td>-6.85db</td>\n",
       "      <td>-5.75db</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy</th>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>danceability</th>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valence</th>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speechiness</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveness</th>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acousticness</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrumentalness</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popularity</th>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  0  \\\n",
       "isrc                                                   GBBPW1200312   \n",
       "artist                                                          !!!   \n",
       "track_name                                Even When the Waters Cold   \n",
       "lyrics            Friends told her she was better off at the bot...   \n",
       "genre                                                       hip hop   \n",
       "album                                                      Thr!!!er   \n",
       "release_date                                        29th April 2013   \n",
       "key                                                           D min   \n",
       "time_signature                                                  4/4   \n",
       "length                                                        03:47   \n",
       "explicit                                                         No   \n",
       "emotion                                                     sadness   \n",
       "tempo                                                           105   \n",
       "loudness_db                                                 -6.85db   \n",
       "energy                                                           83   \n",
       "danceability                                                     71   \n",
       "valence                                                          87   \n",
       "speechiness                                                       4   \n",
       "liveness                                                         16   \n",
       "acousticness                                                     11   \n",
       "instrumentalness                                                  0   \n",
       "popularity                                                       40   \n",
       "\n",
       "                                                                  1  \n",
       "isrc                                                   GBBPW1200314  \n",
       "artist                                                          !!!  \n",
       "track_name                                       One Girl / One Boy  \n",
       "lyrics            Well I heard it, playing soft\\nFrom a drunken ...  \n",
       "genre                                                       hip hop  \n",
       "album                                                      Thr!!!er  \n",
       "release_date                                        29th April 2013  \n",
       "key                                                          A# min  \n",
       "time_signature                                                  4/4  \n",
       "length                                                        04:03  \n",
       "explicit                                                         No  \n",
       "emotion                                                     sadness  \n",
       "tempo                                                           117  \n",
       "loudness_db                                                 -5.75db  \n",
       "energy                                                           85  \n",
       "danceability                                                     70  \n",
       "valence                                                          87  \n",
       "speechiness                                                       4  \n",
       "liveness                                                         32  \n",
       "acousticness                                                      0  \n",
       "instrumentalness                                                  0  \n",
       "popularity                                                       42  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_map = {\n",
    "    \"Artist(s)\":\"artist\",\"artists\":\"artist\",\"artist\":\"artist\",\n",
    "    \"song\":\"track_name\",\"Song\":\"track_name\",\"track_name\":\"track_name\",\n",
    "    \"text\":\"lyrics\",\"Lyrics\":\"lyrics\",\n",
    "    \"Genre\":\"genre\",\"genre\":\"genre\",\n",
    "    \"Album\":\"album\",\"album\":\"album\",\n",
    "    \"ISRC\":\"isrc\",\"isrc\":\"isrc\",\n",
    "    \"Release Date\":\"release_date\",\"release_date\":\"release_date\",\n",
    "    \"Key\":\"key\",\"key\":\"key\",\n",
    "    \"Time signature\":\"time_signature\",\"time_signature\":\"time_signature\",\n",
    "    \"Length\":\"length\",\"length\":\"length\",\n",
    "    \"Explicit\":\"explicit\",\"explicit\":\"explicit\",\n",
    "    \"emotion\":\"emotion\",\n",
    "    \"Tempo\":\"tempo\",\"tempo\":\"tempo\",\n",
    "    \"Loudness (db)\":\"loudness_db\",\"loudness\":\"loudness_db\",\n",
    "    \"Energy\":\"energy\",\"energy\":\"energy\",\n",
    "    \"Danceability\":\"danceability\",\"danceability\":\"danceability\",\n",
    "    \"Positiveness\":\"valence\",\"valence\":\"valence\",\n",
    "    \"Speechiness\":\"speechiness\",\"speechiness\":\"speechiness\",\n",
    "    \"Liveness\":\"liveness\",\"liveness\":\"liveness\",\n",
    "    \"Acousticness\":\"acousticness\",\"acousticness\":\"acousticness\",\n",
    "    \"Instrumentalness\":\"instrumentalness\",\"instrumentalness\":\"instrumentalness\",\n",
    "    \"Popularity\":\"popularity\",\"popularity\":\"popularity\",\n",
    "}\n",
    "def rename_keep(df):\n",
    "    df = df.rename(columns={c: common_map.get(c,c) for c in df.columns})\n",
    "    keep = [\"isrc\",\"artist\",\"track_name\",\"lyrics\",\"genre\",\"album\",\"release_date\",\"key\",\n",
    "            \"time_signature\",\"length\",\"explicit\",\"emotion\",\"tempo\",\"loudness_db\",\n",
    "            \"energy\",\"danceability\",\"valence\",\"speechiness\",\"liveness\",\"acousticness\",\n",
    "            \"instrumentalness\",\"popularity\"]\n",
    "    return df[[c for c in keep if c in df.columns]].copy()\n",
    "\n",
    "df_j2 = rename_keep(df_j2)\n",
    "df_j1 = rename_keep(df_j1)\n",
    "df_csv = rename_keep(df_csv)\n",
    "df_j2.head(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c62609-e36e-4817-885c-2384ddbdc04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okeiy\\AppData\\Local\\Temp\\ipykernel_11852\\2540863833.py:56: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  ts = pd.to_datetime(s, errors=\"ignore\")\n",
      "C:\\Users\\okeiy\\AppData\\Local\\Temp\\ipykernel_11852\\2540863833.py:56: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  ts = pd.to_datetime(s, errors=\"ignore\")\n",
      "C:\\Users\\okeiy\\AppData\\Local\\Temp\\ipykernel_11852\\2540863833.py:56: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  ts = pd.to_datetime(s, errors=\"ignore\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((551443, 24), (498052, 23), (551443, 23))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_df(df):\n",
    "    df = df.copy()\n",
    "    if \"tempo\" in df:          df[\"tempo\"] = df[\"tempo\"].apply(parse_tempo)\n",
    "    if \"loudness_db\" in df:    df[\"loudness_db\"] = df[\"loudness_db\"].apply(parse_loudness_db)\n",
    "    if \"length\" in df:         df[\"length_s\"] = df[\"length\"].apply(parse_length_mmss)\n",
    "    if \"release_date\" in df:   df[\"release_date\"] = df[\"release_date\"].apply(parse_release_date)\n",
    "    for c in [\"energy\",\"danceability\",\"valence\",\"speechiness\",\"liveness\",\n",
    "              \"acousticness\",\"instrumentalness\",\"popularity\"]:\n",
    "        if c in df: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    if \"explicit\" in df:\n",
    "        df[\"explicit\"] = df[\"explicit\"].astype(str).str.strip().str.lower().map(\n",
    "            {\"true\": True,\"1\": True,\"yes\": True,\"y\": True,\"explicit\": True,\n",
    "             \"false\": False,\"0\": False,\"no\": False,\"n\": False}\n",
    "        ).astype(\"boolean\")\n",
    "    for c in [\"artist\",\"track_name\"]:\n",
    "        if c in df: df[c] = df[c].astype(str).str.strip()\n",
    "    df[\"join_key\"] = (df.get(\"artist\",\"\").apply(norm_key) + \" â€” \" +\n",
    "                      df.get(\"track_name\",\"\").apply(norm_key))\n",
    "    if \"isrc\" in df: df[\"isrc\"] = df[\"isrc\"].astype(str).str.strip().str.upper()\n",
    "    return df\n",
    "\n",
    "df_j2 = clean_df(df_j2)\n",
    "df_j1 = clean_df(df_j1)\n",
    "df_csv = clean_df(df_csv)\n",
    "df_j2.shape, df_j1.shape, df_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35eadd5-cf3e-45c5-9d4d-00bc4a20f856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isrc</th>\n",
       "      <th>artist</th>\n",
       "      <th>track_name</th>\n",
       "      <th>album</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>emotion</th>\n",
       "      <th>release_date</th>\n",
       "      <th>key</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness_db</th>\n",
       "      <th>energy</th>\n",
       "      <th>danceability</th>\n",
       "      <th>valence</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>popularity</th>\n",
       "      <th>join_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>406590</th>\n",
       "      <td>USA2P0721820</td>\n",
       "      <td>Sagat</td>\n",
       "      <td>Funk Dat</td>\n",
       "      <td>Funk Dat (Why Is It?)</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>[Intro]\\nFunk dat!\\n\\n[Verse 1]\\nQuestion:\\nWh...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1993-01-01</td>\n",
       "      <td>D# min</td>\n",
       "      <td>4/4</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.30</td>\n",
       "      <td>44</td>\n",
       "      <td>89</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>sagat â€” funk dat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315461</th>\n",
       "      <td>USUM70607498</td>\n",
       "      <td>Method Man,Fat Joe,Styles P</td>\n",
       "      <td>Yameen</td>\n",
       "      <td>4:21...The Day After</td>\n",
       "      <td>hip hop</td>\n",
       "      <td>[Intro: Method Man]\\nYo, I'm bout to hit you w...</td>\n",
       "      <td>love</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>D Maj</td>\n",
       "      <td>4/4</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.09</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>method man,fat joe,styles p â€” yameen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47497</th>\n",
       "      <td>USSM10024329</td>\n",
       "      <td>Bessie Smith</td>\n",
       "      <td>Any Womans Blues</td>\n",
       "      <td>The Complete Recordings, Vol. 1</td>\n",
       "      <td>blues,jazz</td>\n",
       "      <td>My man ain't acting right\\nHe stays out late a...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1991-04-08</td>\n",
       "      <td>B Maj</td>\n",
       "      <td>4/4</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.46</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>bessie smith â€” any womans blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299218</th>\n",
       "      <td>NO5281301050</td>\n",
       "      <td>Madcon</td>\n",
       "      <td>Unbreakable</td>\n",
       "      <td>Icon</td>\n",
       "      <td>hip hop,electropop</td>\n",
       "      <td>[Hook: Tshawe]\\nDon't judge my way\\nCan't take...</td>\n",
       "      <td>joy</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>B min</td>\n",
       "      <td>4/4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>90</td>\n",
       "      <td>68</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>madcon â€” unbreakable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176844</th>\n",
       "      <td>US4D40400300</td>\n",
       "      <td>Gentle Giant</td>\n",
       "      <td>His Last Voyage</td>\n",
       "      <td>Free Hand</td>\n",
       "      <td>progressive rock,rock</td>\n",
       "      <td>Rose in early morning, as the light came throu...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1975-07-01</td>\n",
       "      <td>F Maj</td>\n",
       "      <td>3/4</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.77</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>gentle giant â€” his last voyage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                isrc                       artist        track_name  \\\n",
       "406590  USA2P0721820                        Sagat          Funk Dat   \n",
       "315461  USUM70607498  Method Man,Fat Joe,Styles P            Yameen   \n",
       "47497   USSM10024329                 Bessie Smith  Any Womans Blues   \n",
       "299218  NO5281301050                       Madcon       Unbreakable   \n",
       "176844  US4D40400300                 Gentle Giant   His Last Voyage   \n",
       "\n",
       "                                  album                  genre  \\\n",
       "406590            Funk Dat (Why Is It?)                hip hop   \n",
       "315461             4:21...The Day After                hip hop   \n",
       "47497   The Complete Recordings, Vol. 1             blues,jazz   \n",
       "299218                             Icon     hip hop,electropop   \n",
       "176844                        Free Hand  progressive rock,rock   \n",
       "\n",
       "                                                   lyrics  emotion  \\\n",
       "406590  [Intro]\\nFunk dat!\\n\\n[Verse 1]\\nQuestion:\\nWh...  sadness   \n",
       "315461  [Intro: Method Man]\\nYo, I'm bout to hit you w...     love   \n",
       "47497   My man ain't acting right\\nHe stays out late a...  sadness   \n",
       "299218  [Hook: Tshawe]\\nDon't judge my way\\nCan't take...      joy   \n",
       "176844  Rose in early morning, as the light came throu...  sadness   \n",
       "\n",
       "       release_date     key time_signature  ...  loudness_db  energy  \\\n",
       "406590   1993-01-01  D# min            4/4  ...       -15.30      44   \n",
       "315461   2006-01-01   D Maj            4/4  ...        -7.09      67   \n",
       "47497    1991-04-08   B Maj            4/4  ...       -18.46       3   \n",
       "299218   2013-09-26   B min            4/4  ...        -1.24      90   \n",
       "176844   1975-07-01   F Maj            3/4  ...       -11.77      36   \n",
       "\n",
       "        danceability  valence  speechiness  liveness  acousticness  \\\n",
       "406590            89       78           10         4            47   \n",
       "315461            61       73           32         5             9   \n",
       "47497             56       33            4        15           100   \n",
       "299218            68       34            6         8             4   \n",
       "176844            32       42            4        11            74   \n",
       "\n",
       "        instrumentalness  popularity                              join_key  \n",
       "406590                 2          27                      sagat â€” funk dat  \n",
       "315461                 0          24  method man,fat joe,styles p â€” yameen  \n",
       "47497                  3          11       bessie smith â€” any womans blues  \n",
       "299218                 0           6                  madcon â€” unbreakable  \n",
       "176844                88          10        gentle giant â€” his last voyage  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (445069, 23)\n"
     ]
    }
   ],
   "source": [
    "def smart_merge(left, right):\n",
    "    left = left.copy(); right = right.copy()\n",
    "    l_isrc = left[left[\"isrc\"].notna()] if \"isrc\" in left else left.iloc[0:0]\n",
    "    l_no   = left[left[\"isrc\"].isna()]  if \"isrc\" in left else left\n",
    "    r_isrc = right[right[\"isrc\"].notna()] if \"isrc\" in right else right.iloc[0:0]\n",
    "    r_no   = right[right[\"isrc\"].isna()]  if \"isrc\" in right else right\n",
    "\n",
    "    m1 = pd.merge(l_isrc, r_isrc, on=\"isrc\", how=\"left\", suffixes=(\"\", \"_r\")) if len(l_isrc) and len(r_isrc) else l_isrc\n",
    "    m2 = pd.merge(l_no,   r_no,   on=\"join_key\", how=\"left\", suffixes=(\"\", \"_r\")) if len(l_no) and len(r_no) else l_no\n",
    "    merged = pd.concat([m1, m2], ignore_index=True)\n",
    "\n",
    "    for c in list(merged.columns):\n",
    "        if c.endswith(\"_r\"):\n",
    "            base = c[:-2]\n",
    "            if base in merged.columns:\n",
    "                merged[base] = merged[base].combine_first(merged[c])\n",
    "            merged.drop(columns=[c], inplace=True, errors=\"ignore\")\n",
    "    return merged\n",
    "\n",
    "merged = smart_merge(df_j2, df_j1)\n",
    "merged = smart_merge(merged, df_csv)\n",
    "\n",
    "final_cols = [\"isrc\",\"artist\",\"track_name\",\"album\",\"genre\",\"lyrics\",\"emotion\",\n",
    "              \"release_date\",\"key\",\"time_signature\",\"length_s\",\"explicit\",\n",
    "              \"tempo\",\"loudness_db\",\"energy\",\"danceability\",\"valence\",\"speechiness\",\n",
    "              \"liveness\",\"acousticness\",\"instrumentalness\",\"popularity\",\"join_key\"]\n",
    "final = merged[[c for c in final_cols if c in merged.columns]].copy()\n",
    "\n",
    "if \"isrc\" in final:\n",
    "    final = final.sort_values([\"isrc\",\"release_date\"], na_position=\"last\") \\\n",
    "                 .drop_duplicates(subset=[\"isrc\"], keep=\"first\")\n",
    "final = final.sort_values([\"join_key\",\"release_date\"], na_position=\"last\") \\\n",
    "             .drop_duplicates(subset=[\"join_key\"], keep=\"first\")\n",
    "\n",
    "display(final.sample(5))\n",
    "print(\"Shape:\", final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf3056a-14d1-4df8-adcd-11ffdb9f9bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data\\interim\\spotify_clean.pkl data\\interim\\spotify_50k.pkl data\\interim\\spotify_clean.csv data\\interim\\spotify_50k.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "full_pkl   = Path(\"data/interim/spotify_clean.pkl\")\n",
    "subset_pkl = Path(\"data/interim/spotify_50k.pkl\")\n",
    "full_csv   = Path(\"data/interim/spotify_clean.csv\")\n",
    "subset_csv = Path(\"data/interim/spotify_50k.csv\")\n",
    "full_pkl.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "n_subset = min(50000, len(final))\n",
    "subset = final.sample(n_subset, random_state=42)\n",
    "\n",
    "final.to_pickle(full_pkl)\n",
    "subset.to_pickle(subset_pkl)\n",
    "final.to_csv(full_csv, index=False)\n",
    "subset.to_csv(subset_csv, index=False)\n",
    "\n",
    "print(\"Saved:\", full_pkl, subset_pkl, full_csv, subset_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94467a19-164d-4a0b-8fb6-849e83f70c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,\n",
       " ['isrc',\n",
       "  'artist',\n",
       "  'track_name',\n",
       "  'album',\n",
       "  'genre',\n",
       "  'lyrics',\n",
       "  'emotion',\n",
       "  'release_date',\n",
       "  'key',\n",
       "  'time_signature',\n",
       "  'length_s',\n",
       "  'explicit'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"data/interim/spotify_50k.pkl\")\n",
    "len(df), df.columns.tolist()[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be3a8dc0-bc7c-4d89-b228-63d3fad14a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okeiy\\.conda\\envs\\harmonyai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\okeiy\\.conda\\envs\\harmonyai\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\okeiy\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [5:02:01<00:00, 184.91s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [10:43<00:00,  6.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50000, 384), (50000, 384))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "texts_lyrics = df[\"lyrics\"].fillna(df[\"track_name\"] + \" \" + df[\"artist\"])\n",
    "texts_meta   = (df[\"artist\"].fillna(\"\") + \" | \"\n",
    "                + df.get(\"genre\", pd.Series([\"\"]*len(df))).fillna(\"\") + \" | \"\n",
    "                + df[\"track_name\"].fillna(\"\"))\n",
    "\n",
    "batch = 512\n",
    "def batched_encode(texts):\n",
    "    out = []\n",
    "    for i in tqdm(range(0, len(texts), batch)):\n",
    "        chunk = texts.iloc[i:i+batch].tolist()\n",
    "        E = model.encode(chunk, normalize_embeddings=True, show_progress_bar=False)\n",
    "        out.append(E)\n",
    "    return np.vstack(out).astype(\"float32\")\n",
    "\n",
    "lyrics_emb = batched_encode(texts_lyrics)\n",
    "meta_emb   = batched_encode(texts_meta)\n",
    "lyrics_emb.shape, meta_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd6e5e9-9fc3-49e5-acc0-5bf5e2f1cad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 11), (50000, 7))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cols = [c for c in [\n",
    "    \"energy\",\"danceability\",\"valence\",\"speechiness\",\"liveness\",\n",
    "    \"acousticness\",\"instrumentalness\",\"popularity\",\"tempo\",\"loudness_db\",\"length_s\"\n",
    "] if c in df.columns]\n",
    "\n",
    "X_num = df[num_cols].fillna(df[num_cols].median())\n",
    "scaler = StandardScaler()\n",
    "X_num_scaled = scaler.fit_transform(X_num).astype(\"float32\")\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "if \"emotion\" in df.columns:\n",
    "    emo_lists = df[\"emotion\"].fillna(\"\").astype(str).str.split(\",\").apply(\n",
    "        lambda xs: [x.strip().lower() for x in xs if x.strip()]\n",
    "    )\n",
    "    mlb = MultiLabelBinarizer(sparse_output=False)\n",
    "    emo_mat = mlb.fit_transform(emo_lists).astype(\"float32\")\n",
    "else:\n",
    "    emo_mat = np.zeros((len(df), 0), dtype=\"float32\")\n",
    "\n",
    "X_num_scaled.shape, emo_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec009496-0861-4008-b0f3-d4346435c1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 402), (50000, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "w_lyrics, w_meta, w_num, w_emo = 0.6, 0.2, 0.15, 0.05\n",
    "X_num_n = normalize(X_num_scaled) if X_num_scaled.shape[1] else X_num_scaled\n",
    "emo_n   = normalize(emo_mat) if emo_mat.shape[1] else emo_mat\n",
    "\n",
    "text_block = (w_lyrics*lyrics_emb + w_meta*meta_emb)\n",
    "hybrid = np.hstack([text_block, w_num*X_num_n, w_emo*emo_n]).astype(\"float32\")\n",
    "hybrid = normalize(hybrid).astype(\"float32\")\n",
    "\n",
    "np.save(\"data/processed/hybrid_emb_50k.npy\", hybrid)\n",
    "\n",
    "items = df[[\"artist\",\"track_name\",\"album\",\"genre\",\"release_date\"]].copy().reset_index(drop=True)\n",
    "items.to_pickle(\"data/processed/items_50k.pkl\")\n",
    "hybrid.shape, items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ab4ad2-f69d-4a9d-b6c1-4d83d1824cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402, 50000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss, numpy as np\n",
    "\n",
    "xb = np.load(\"data/processed/hybrid_emb_50k.npy\")\n",
    "d = xb.shape[1]\n",
    "index = faiss.IndexFlatIP(d)   # cosine if L2-normalized\n",
    "index.add(xb)\n",
    "faiss.write_index(index, \"data/processed/faiss_ip_50k.index\")\n",
    "d, index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "667b9511-8237-4be5-967a-053f2dce23bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts ready in app/artifacts \n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "text_dim = lyrics_emb.shape[1]\n",
    "tail_dim = hybrid.shape[1] - (text_dim + text_dim)\n",
    "\n",
    "class HybridQueryEncoder:\n",
    "    def __init__(self, model_name, w_lyrics=0.6, w_meta=0.2, tail_dim=0):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.w_lyrics, self.w_meta, self.tail_dim = w_lyrics, w_meta, tail_dim\n",
    "    def encode(self, text: str):\n",
    "        E = self.model.encode([text], normalize_embeddings=True).astype(\"float32\")\n",
    "        q_text = self.w_lyrics*E + self.w_meta*E\n",
    "        tail = np.zeros((1, self.tail_dim), dtype=\"float32\")\n",
    "        q = np.hstack([q_text, tail])\n",
    "        return normalize(q).astype(\"float32\")\n",
    "\n",
    "enc = HybridQueryEncoder(model_name, 0.6, 0.2, tail_dim)\n",
    "joblib.dump(enc, \"app/artifacts/query_encoder.pkl\")\n",
    "\n",
    "import shutil\n",
    "shutil.copy(\"data/processed/faiss_ip_50k.index\", \"app/artifacts/faiss_ip_50k.index\")\n",
    "shutil.copy(\"data/processed/items_50k.pkl\",       \"app/artifacts/items_50k.pkl\")\n",
    "print(\"Artifacts ready in app/artifacts \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e7ebdc6-150b-4b7a-9d99-fb213523720d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilt encoder\n",
      "hybrid_dim: 402 | text_dim: 384 | tail_dim: 18\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, joblib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# 1) figure out dimensions from your saved artifacts\n",
    "hybrid = np.load(\"data/processed/hybrid_emb_50k.npy\")\n",
    "hybrid_dim = hybrid.shape[1]\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "_text_model = SentenceTransformer(model_name)\n",
    "text_dim = _text_model.get_sentence_embedding_dimension()\n",
    "\n",
    "# since we SUMMED lyrics+meta, tail = hybrid - text_dim\n",
    "tail_dim = int(hybrid_dim - text_dim)\n",
    "assert tail_dim >= 0, (hybrid_dim, text_dim, tail_dim)\n",
    "\n",
    "# 2) rebuild a consistent query encoder\n",
    "class HybridQueryEncoder:\n",
    "    def __init__(self, model_name, w_lyrics=0.6, w_meta=0.2, tail_dim=0):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.w_lyrics = w_lyrics\n",
    "        self.w_meta = w_meta\n",
    "        self.tail_dim = tail_dim\n",
    "    def encode(self, text: str):\n",
    "        # we used the SAME embedding for lyrics+meta and then weighted SUM\n",
    "        E = self.model.encode([text], normalize_embeddings=True).astype(\"float32\")  # (1, text_dim)\n",
    "        q_text = (self.w_lyrics + self.w_meta) * E                                  # (1, text_dim)\n",
    "        tail = np.zeros((1, self.tail_dim), dtype=\"float32\")                        # (1, tail_dim)\n",
    "        q = np.hstack([q_text, tail])                                               # (1, hybrid_dim)\n",
    "        return normalize(q).astype(\"float32\")\n",
    "\n",
    "enc = HybridQueryEncoder(model_name, w_lyrics=0.6, w_meta=0.2, tail_dim=tail_dim)\n",
    "\n",
    "# 3) overwrite the old encoder file\n",
    "joblib.dump(enc, \"app/artifacts/query_encoder.pkl\");\n",
    "\n",
    "print(\"Rebuilt encoder\")\n",
    "print(\"hybrid_dim:\", hybrid_dim, \"| text_dim:\", text_dim, \"| tail_dim:\", tail_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0355163-012f-49b0-bf37-3e0bb7f2bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "src_files = {\n",
    "    \"data/processed/items_50k.pkl\": \"app/artifacts/items_50k.pkl\",\n",
    "    \"data/processed/faiss_ip_50k.index\": \"app/artifacts/faiss_ip_50k.index\",\n",
    "    # encoder is already in the right place â€” copy only if itâ€™s elsewhere\n",
    "}\n",
    "\n",
    "Path(\"app/artifacts\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for src, dst in src_files.items():\n",
    "    src, dst = Path(src), Path(dst)\n",
    "    if not dst.exists():\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\" Copied {src.name} â†’ {dst.parent}\")\n",
    "    else:\n",
    "        print(f\" Skipped (already exists): {dst.name}\")\n",
    "\n",
    "print(\"\\n All artifacts are now in app/artifacts/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46183de5-5eda-4265-96d8-ceb0f7ea7f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harmonyai (conda)",
   "language": "python",
   "name": "harmonyai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
